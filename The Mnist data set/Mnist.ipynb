{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccbca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09abbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1967015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version 3.0.1 of dataset mnist in data_dir C:\\Users\\LENOVO\\tensorflow_datasets. Using currently defined version 1.0.0.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset,mnist_info = tfds.load(name ='mnist' , with_info =True , as_supervised = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae640f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train ,mnist_test = mnist_dataset['train'] , mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b8b44f",
   "metadata": {},
   "source": [
    "mnist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a6c3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    version=1.0.0,\n",
       "    description='The MNIST database of handwritten digits.',\n",
       "    urls=['https://storage.googleapis.com/cvdf-datasets/mnist/'],\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    total_num_examples=70000,\n",
       "    splits={\n",
       "        'test': 10000,\n",
       "        'train': 60000,\n",
       "    },\n",
       "    supervised_keys=('image', 'label'),\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6474d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image , label):\n",
    "    image = tf.cast(image , tf.float32)\n",
    "    image/=256.\n",
    "    return image , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6caa50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation = mnist_train.map(scale)\n",
    "test = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05e786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples , tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9f3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 0.1 * mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples , tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00597e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation =train_and_validation.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf7a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =train_and_validation.skip(num_validation_samples)\n",
    "validation_data =train_and_validation.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a34247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =train_data.batch(BATCH_SIZE)\n",
    "validation_data =validation_data.batch(BATCH_SIZE)\n",
    "test_data = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef2d44",
   "metadata": {},
   "source": [
    "## create the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed4bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\lenovo\\anaconda3\\envs\\pytorch\\lib\\site-packages (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eede904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "509864c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      "Layer (type)                     Output Shape                  Param #     \n",
      "===========================================================================\n",
      "conv2d (Conv2D)                  (None, 24, 24, 50)            1300        \n",
      "___________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)     (None, 12, 12, 50)            0           \n",
      "___________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 10, 10, 50)            22550       \n",
      "___________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 5, 5, 50)              0           \n",
      "___________________________________________________________________________\n",
      "flatten (Flatten)                (None, 1250)                  0           \n",
      "___________________________________________________________________________\n",
      "dense (Dense)                    (None, 10)                    12510       \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length =75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e8a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b298ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss=loss_fn , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ca626b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor= 'val_loss',\n",
    "    mode  = 'auto',\n",
    "    min_delta = 0 ,\n",
    "    patience = 2 ,\n",
    "    verbose = 0 ,\n",
    "    restore_best_weights = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbab7223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 31s - loss: 0.2744 - accuracy: 0.9216 - val_loss: 0.0868 - val_accuracy: 0.9760\n",
      "Epoch 2/20\n",
      "422/422 - 30s - loss: 0.0718 - accuracy: 0.9787 - val_loss: 0.0574 - val_accuracy: 0.9818\n",
      "Epoch 3/20\n",
      "422/422 - 29s - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 4/20\n",
      "422/422 - 28s - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.0425 - val_accuracy: 0.9870\n",
      "Epoch 5/20\n",
      "422/422 - 27s - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.0315 - val_accuracy: 0.9888\n",
      "Epoch 6/20\n",
      "422/422 - 33s - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0225 - val_accuracy: 0.9932\n",
      "Epoch 7/20\n",
      "422/422 - 34s - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0187 - val_accuracy: 0.9943\n",
      "Epoch 8/20\n",
      "422/422 - 35s - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0323 - val_accuracy: 0.9917\n",
      "Epoch 9/20\n",
      "422/422 - 36s - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0156 - val_accuracy: 0.9955\n",
      "Epoch 10/20\n",
      "422/422 - 33s - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0126 - val_accuracy: 0.9958\n",
      "Epoch 11/20\n",
      "422/422 - 33s - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0122 - val_accuracy: 0.9963\n",
      "Epoch 12/20\n",
      "422/422 - 34s - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 13/20\n",
      "422/422 - 33s - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0098 - val_accuracy: 0.9972\n",
      "Epoch 14/20\n",
      "422/422 - 32s - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0094 - val_accuracy: 0.9968\n",
      "Epoch 15/20\n",
      "422/422 - 32s - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 16/20\n",
      "422/422 - 33s - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 17/20\n",
      "422/422 - 34s - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0046 - val_accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "422/422 - 32s - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 19/20\n",
      "422/422 - 33s - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0042 - val_accuracy: 0.9983\n",
      "Epoch 20/20\n",
      "422/422 - 35s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0043 - val_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d4cd2c970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "train_data , epochs = NUM_EPOCHS , callbacks = [early_stopping]  ,\n",
    "validation_data = validation_data\n",
    "    ,verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5148d71",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6fb12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0367 - accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "#use evaluate method\n",
    "test_loss , test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e08e9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.0367 , test_accuracy : 99.0100\n"
     ]
    }
   ],
   "source": [
    "print(f\"test loss : {test_loss:.4f} , test_accuracy : {test_accuracy*100 :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abc4fc",
   "metadata": {},
   "source": [
    "# plotting images and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c460f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0106afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (128,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c891ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d53916280>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEfklEQVR4nO2dyyttURzH77mEkaQ8iwxMGDAgExPlkUzMlD9AFCKZmGDglIFHEiMDShkoZaYwMiAZKe+kKAwMDDzyPHf8/Z17N7ttn7PP/X4/s2+HtZY+Lb/W2muvE4pEIr8EH7/jPQARHySeFIknReJJkXhSJJ6UZKcPQ6GQ1noJTCQSCf3rM814UiSeFIknReJJkXhSJJ4UiSdF4kmReFIknhSJJ0XiSZF4UiSeFIknReJJkXhSJJ4Ux6NXiUZpaSnkgYEByFVVVZDT0tIgFxQUQA6F8OTS4uIi5HA4DPn4+Pj7g40zmvGkSDwpEk9KyOlt2aAfr25tbYW8sLAAOSkpydf+b29vIdfX10M+PDz0tf+v0PFqEYXEkyLxpCT0Ot7WcL9ruiU3Nxfy+vo65IaGBsgHBwe+j+m7aMaTIvGkSDwpCV3jT09PIdsaa9fVm5ubkGdmZiCvrKx4Go+t+Wtra5AbGxshx7Pma8aTIvGkSDwpCb1Xb7HP4zc2NiBnZGRAfnx8hJyZmQn57u4O8tPTE+TCwkJX47u+vobsd83XXr2IQuJJkXhSErrGDw8PQ+7o6ICclZXlqf29vT3IbW1tkFdXVyG7rflXV1eQi4qKXP3+V6jGiygknhSJJyWh9uptTbfn5pOT/f1z9vf3Ic/Pz0MeHBx01Z7dV4glmvGkSDwpEk9KoGv80NAQZK81fW5uDvL09DTk/v5+yCUlJY7tjY6OQq6srITc1NTkanyxRDOeFIknReJJCXSN7+rqguy1pvf19UG2z+NtfyMjI47tv7y8QL6/v3c1vniiGU+KxJMSqH/1LS0tkNPT0z21Z5dr9l+75eHhAfLExISn/oOMZjwpEk+KxJMSqBqfn58P2e3yzR6Hfn5+9jSey8tLx8/tUava2lpP/cUSzXhSJJ4UiSclUDXeK/bK0fPzc1/7a29vh5yTk+P48+/v75DHxsZ+fEzfRTOeFIknReJJCdQrVLu7u5ArKipc/b49KmWvSvGKfcVpa2sLst2HsNjXoMvKyn5kXP9Cr1CJKCSeFIknJa7r+ObmZsjl5eVxGsnfKS4uhmyvR/uqpltmZ2c9j+mn0IwnReJJkXhS4lrjz87OIH98fED2+7VnS15eHuTu7m7IdXV1sRyOr2jGkyLxpEg8KXGt8fbrud7e3iCnpqa6ai87OxvyxcUFZHv1SGdnJ2R7nZm9htxin6+fnJxAnpychLy9ve3YXizRjCdF4kmReFIC9Tz+5uYGsq3ZblleXoZcU1MD2e2Vp3afwV6F4va6M7/R83gRhcSTIvGkBKrG9/b2Qh4fH49l91E13H4VydTUFGR7HVvQUI0XUUg8KRJPSqDenbM19vX1FXJKSoqn9j8/PyHbvXZ7vVk4HPbUX5DRjCdF4kkJ1HLuK3p6eiBXV1dDto9dj46OIO/s7EBeWlr6ucEFEC3nRBQST4rEk5JQNV64QzVeRCHxpEg8KRJPisSTIvGkSDwpEk+KxJMi8aRIPCmOe/Xi/0UznhSJJ0XiSZF4UiSeFIkn5Q+jRSuS8UBSqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the image to be displayed and tested\n",
    "i = 55\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1] ,cmap = \"gray\" , aspect = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35f9c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (recall that we incorporated the softmaxt activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4acc50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
